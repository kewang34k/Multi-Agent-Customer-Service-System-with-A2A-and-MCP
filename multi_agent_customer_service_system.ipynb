{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Customer Service System with A2A and MCP\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "This notebook implements a production-ready multi-agent customer service system with:\n",
    "\n",
    "### Agents:\n",
    "1. **Router Agent (Orchestrator)**: Routes queries and coordinates multi-agent responses\n",
    "2. **Customer Data Agent (Specialist)**: Manages customer data via MCP protocol\n",
    "3. **Support Agent (Specialist)**: Handles support queries and escalations\n",
    "\n",
    "### Key Features:\n",
    "- Agent-to-Agent (A2A) Communication\n",
    "- Model Context Protocol (MCP) for data access\n",
    "- Intelligent query routing\n",
    "- Multi-agent coordination\n",
    "- State management with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q -U langgraph langchain-openai langchain-core pydantic typing-extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "from typing import Literal, TypedDict, Annotated, Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "print(\"âœ“ Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCP Server Implementation\n",
    "\n",
    "Model Context Protocol (MCP) provides standardized access to customer data.\n",
    "In production, this would connect to a real database or API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Data Models\n",
    "class CustomerRecord(BaseModel):\n",
    "    \"\"\"Customer data schema\"\"\"\n",
    "    customer_id: str\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "    tier: Literal[\"basic\", \"premium\", \"enterprise\"]\n",
    "    account_status: Literal[\"active\", \"suspended\", \"closed\"]\n",
    "    join_date: str\n",
    "    total_orders: int\n",
    "    lifetime_value: float\n",
    "    support_tickets: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "\n",
    "class MCPServer:\n",
    "    \"\"\"Simulated MCP Server for Customer Data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Simulated customer database\n",
    "        self.customers = {\n",
    "            \"CUST001\": CustomerRecord(\n",
    "                customer_id=\"CUST001\",\n",
    "                name=\"Alice Johnson\",\n",
    "                email=\"alice.johnson@email.com\",\n",
    "                phone=\"+1-555-0101\",\n",
    "                tier=\"premium\",\n",
    "                account_status=\"active\",\n",
    "                join_date=\"2023-01-15\",\n",
    "                total_orders=47,\n",
    "                lifetime_value=12450.00,\n",
    "                support_tickets=[\n",
    "                    {\"id\": \"TK001\", \"status\": \"resolved\", \"issue\": \"Shipping delay\"},\n",
    "                    {\"id\": \"TK015\", \"status\": \"open\", \"issue\": \"Product defect\"}\n",
    "                ]\n",
    "            ),\n",
    "            \"CUST002\": CustomerRecord(\n",
    "                customer_id=\"CUST002\",\n",
    "                name=\"Bob Martinez\",\n",
    "                email=\"bob.m@company.com\",\n",
    "                phone=\"+1-555-0202\",\n",
    "                tier=\"enterprise\",\n",
    "                account_status=\"active\",\n",
    "                join_date=\"2022-06-10\",\n",
    "                total_orders=203,\n",
    "                lifetime_value=87600.00,\n",
    "                support_tickets=[\n",
    "                    {\"id\": \"TK042\", \"status\": \"resolved\", \"issue\": \"Billing inquiry\"}\n",
    "                ]\n",
    "            ),\n",
    "            \"CUST003\": CustomerRecord(\n",
    "                customer_id=\"CUST003\",\n",
    "                name=\"Carol White\",\n",
    "                email=\"carol.white@mail.com\",\n",
    "                phone=\"+1-555-0303\",\n",
    "                tier=\"basic\",\n",
    "                account_status=\"active\",\n",
    "                join_date=\"2024-02-20\",\n",
    "                total_orders=3,\n",
    "                lifetime_value=287.50,\n",
    "                support_tickets=[]\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def get_customer(self, customer_id: str) -> Optional[CustomerRecord]:\n",
    "        \"\"\"Retrieve customer by ID via MCP protocol\"\"\"\n",
    "        return self.customers.get(customer_id)\n",
    "    \n",
    "    def search_customer(self, email: str = None, phone: str = None) -> Optional[CustomerRecord]:\n",
    "        \"\"\"Search customer by email or phone\"\"\"\n",
    "        for customer in self.customers.values():\n",
    "            if email and customer.email == email:\n",
    "                return customer\n",
    "            if phone and customer.phone == phone:\n",
    "                return customer\n",
    "        return None\n",
    "    \n",
    "    def update_customer(self, customer_id: str, updates: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Update customer record\"\"\"\n",
    "        if customer_id not in self.customers:\n",
    "            return False\n",
    "        \n",
    "        customer = self.customers[customer_id]\n",
    "        for key, value in updates.items():\n",
    "            if hasattr(customer, key):\n",
    "                setattr(customer, key, value)\n",
    "        return True\n",
    "    \n",
    "    def add_support_ticket(self, customer_id: str, ticket: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Add support ticket to customer record\"\"\"\n",
    "        if customer_id not in self.customers:\n",
    "            return False\n",
    "        \n",
    "        self.customers[customer_id].support_tickets.append(ticket)\n",
    "        return True\n",
    "\n",
    "# Initialize MCP Server\n",
    "mcp_server = MCPServer()\n",
    "print(\"âœ“ MCP Server initialized with\", len(mcp_server.customers), \"customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agent State Schema\n",
    "\n",
    "Defines the shared state that flows through the multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryIntent(str, Enum):\n",
    "    \"\"\"Types of customer queries\"\"\"\n",
    "    ACCOUNT_INFO = \"account_info\"\n",
    "    ORDER_STATUS = \"order_status\"\n",
    "    TECHNICAL_SUPPORT = \"technical_support\"\n",
    "    BILLING = \"billing\"\n",
    "    GENERAL_INQUIRY = \"general_inquiry\"\n",
    "    COMPLAINT = \"complaint\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Shared state across all agents\"\"\"\n",
    "    # Input\n",
    "    query: str\n",
    "    customer_identifier: Optional[str]  # ID, email, or phone\n",
    "    \n",
    "    # Router decisions\n",
    "    intent: Optional[str]\n",
    "    requires_data_agent: bool\n",
    "    requires_support_agent: bool\n",
    "    \n",
    "    # Customer data (from Data Agent)\n",
    "    customer_data: Optional[Dict[str, Any]]\n",
    "    \n",
    "    # Agent responses\n",
    "    data_agent_response: Optional[str]\n",
    "    support_agent_response: Optional[str]\n",
    "    \n",
    "    # Final output\n",
    "    response: str\n",
    "    escalation_needed: bool\n",
    "    \n",
    "    # Workflow tracking\n",
    "    current_phase: str\n",
    "    agents_consulted: List[str]\n",
    "\n",
    "print(\"âœ“ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Router Agent (Orchestrator)\n",
    "\n",
    "The Router Agent analyzes queries and coordinates the workflow between specialist agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for Router\n",
    "router_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "ROUTER_SYSTEM_PROMPT = \"\"\"You are the Router Agent in a customer service system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze customer queries to determine intent\n",
    "2. Identify which specialist agents are needed:\n",
    "   - Customer Data Agent: For account info, order history, customer details\n",
    "   - Support Agent: For technical issues, complaints, general support\n",
    "3. Extract customer identifiers (ID, email, phone) if present\n",
    "4. Coordinate responses from multiple agents when needed\n",
    "\n",
    "Intent categories:\n",
    "- account_info: Account status, profile updates\n",
    "- order_status: Order tracking, delivery questions\n",
    "- technical_support: Product issues, troubleshooting\n",
    "- billing: Payment, invoices, refunds\n",
    "- general_inquiry: Product info, policies\n",
    "- complaint: Service complaints, escalations\n",
    "\n",
    "Return your analysis in JSON format:\n",
    "{\n",
    "  \"intent\": \"<intent_category>\",\n",
    "  \"requires_data_agent\": true/false,\n",
    "  \"requires_support_agent\": true/false,\n",
    "  \"customer_identifier\": \"<ID/email/phone or null>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def router_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Router Agent: Analyze query and determine routing\"\"\"\n",
    "    print(\"\\nðŸ”€ ROUTER AGENT\")\n",
    "    print(f\"   Query: {state['query']}\")\n",
    "    \n",
    "    # Analyze query using LLM\n",
    "    response = router_llm.invoke([\n",
    "        SystemMessage(content=ROUTER_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"Analyze this customer query: {state['query']}\")\n",
    "    ])\n",
    "    \n",
    "    # Parse LLM response\n",
    "    try:\n",
    "        analysis = json.loads(response.content)\n",
    "    except:\n",
    "        # Fallback if JSON parsing fails\n",
    "        analysis = {\n",
    "            \"intent\": \"general_inquiry\",\n",
    "            \"requires_data_agent\": False,\n",
    "            \"requires_support_agent\": True,\n",
    "            \"customer_identifier\": state.get('customer_identifier')\n",
    "        }\n",
    "    \n",
    "    print(f\"   Intent: {analysis['intent']}\")\n",
    "    print(f\"   Data Agent needed: {analysis['requires_data_agent']}\")\n",
    "    print(f\"   Support Agent needed: {analysis['requires_support_agent']}\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"intent\": analysis[\"intent\"],\n",
    "        \"requires_data_agent\": analysis[\"requires_data_agent\"],\n",
    "        \"requires_support_agent\": analysis[\"requires_support_agent\"],\n",
    "        \"customer_identifier\": analysis.get(\"customer_identifier\") or state.get('customer_identifier'),\n",
    "        \"current_phase\": \"routing_complete\",\n",
    "        \"agents_consulted\": [\"router\"]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Router Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Customer Data Agent (Specialist)\n",
    "\n",
    "The Data Agent interfaces with the MCP server to retrieve and update customer information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for Data Agent\n",
    "data_agent_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "DATA_AGENT_SYSTEM_PROMPT = \"\"\"You are the Customer Data Agent.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Access customer data via MCP protocol\n",
    "2. Retrieve customer information (profile, orders, history)\n",
    "3. Update customer records when authorized\n",
    "4. Validate data integrity\n",
    "5. Provide context to other agents\n",
    "\n",
    "You have access to:\n",
    "- Customer profiles\n",
    "- Order history\n",
    "- Support ticket history\n",
    "- Account status\n",
    "\n",
    "Always protect sensitive data and follow privacy guidelines.\n",
    "\"\"\"\n",
    "\n",
    "def customer_data_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Customer Data Agent: Retrieve and manage customer data via MCP\"\"\"\n",
    "    print(\"\\nðŸ’¾ CUSTOMER DATA AGENT\")\n",
    "    \n",
    "    customer_identifier = state.get('customer_identifier')\n",
    "    \n",
    "    if not customer_identifier:\n",
    "        print(\"   âš ï¸  No customer identifier provided\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"data_agent_response\": \"Unable to retrieve customer data: No identifier provided\",\n",
    "            \"customer_data\": None,\n",
    "            \"agents_consulted\": state['agents_consulted'] + [\"data_agent\"]\n",
    "        }\n",
    "    \n",
    "    # Try to retrieve customer data via MCP\n",
    "    customer = None\n",
    "    \n",
    "    # Check if identifier is customer ID\n",
    "    if customer_identifier.startswith(\"CUST\"):\n",
    "        customer = mcp_server.get_customer(customer_identifier)\n",
    "    # Check if identifier is email\n",
    "    elif \"@\" in customer_identifier:\n",
    "        customer = mcp_server.search_customer(email=customer_identifier)\n",
    "    # Check if identifier is phone\n",
    "    else:\n",
    "        customer = mcp_server.search_customer(phone=customer_identifier)\n",
    "    \n",
    "    if not customer:\n",
    "        print(f\"   âŒ Customer not found: {customer_identifier}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"data_agent_response\": f\"Customer not found with identifier: {customer_identifier}\",\n",
    "            \"customer_data\": None,\n",
    "            \"agents_consulted\": state['agents_consulted'] + [\"data_agent\"]\n",
    "        }\n",
    "    \n",
    "    # Convert customer data to dict\n",
    "    customer_dict = customer.dict()\n",
    "    \n",
    "    print(f\"   âœ“ Found customer: {customer.name}\")\n",
    "    print(f\"   Tier: {customer.tier} | Status: {customer.account_status}\")\n",
    "    print(f\"   Orders: {customer.total_orders} | LTV: ${customer.lifetime_value:,.2f}\")\n",
    "    \n",
    "    # Generate contextual response using LLM\n",
    "    response = data_agent_llm.invoke([\n",
    "        SystemMessage(content=DATA_AGENT_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"\"\"Customer Query: {state['query']}\n",
    "        \n",
    "Customer Data:\n",
    "{json.dumps(customer_dict, indent=2)}\n",
    "\n",
    "Provide a summary of relevant customer information for this query.\"\"\")\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"customer_data\": customer_dict,\n",
    "        \"data_agent_response\": response.content,\n",
    "        \"current_phase\": \"data_retrieved\",\n",
    "        \"agents_consulted\": state['agents_consulted'] + [\"data_agent\"]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Customer Data Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Agent (Specialist)\n",
    "\n",
    "The Support Agent handles customer inquiries, provides solutions, and can escalate complex issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for Support Agent\n",
    "support_agent_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)\n",
    "\n",
    "SUPPORT_AGENT_SYSTEM_PROMPT = \"\"\"You are the Support Agent in a customer service system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Handle customer support queries professionally\n",
    "2. Provide solutions and recommendations\n",
    "3. Use customer context from Data Agent when available\n",
    "4. Escalate complex or sensitive issues\n",
    "5. Document support interactions\n",
    "\n",
    "Escalation criteria:\n",
    "- Legal or compliance issues\n",
    "- High-value customer complaints (enterprise tier)\n",
    "- Technical issues requiring engineering\n",
    "- Requests for refunds over $500\n",
    "\n",
    "Always be:\n",
    "- Professional and empathetic\n",
    "- Clear and concise\n",
    "- Solution-oriented\n",
    "- Privacy-conscious\n",
    "\"\"\"\n",
    "\n",
    "def support_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"Support Agent: Handle customer support queries\"\"\"\n",
    "    print(\"\\nðŸŽ§ SUPPORT AGENT\")\n",
    "    \n",
    "    # Build context from customer data if available\n",
    "    context = \"\"\n",
    "    if state.get('customer_data'):\n",
    "        customer = state['customer_data']\n",
    "        context = f\"\"\"\\n\\nCustomer Context:\n",
    "- Name: {customer['name']}\n",
    "- Tier: {customer['tier']}\n",
    "- Account Status: {customer['account_status']}\n",
    "- Total Orders: {customer['total_orders']}\n",
    "- Open Tickets: {len([t for t in customer.get('support_tickets', []) if t['status'] == 'open'])}\n",
    "\"\"\"\n",
    "        print(f\"   âœ“ Using customer context for {customer['name']}\")\n",
    "    \n",
    "    # Generate support response\n",
    "    response = support_agent_llm.invoke([\n",
    "        SystemMessage(content=SUPPORT_AGENT_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"\"\"Customer Query: {state['query']}\n",
    "        \n",
    "Intent: {state.get('intent', 'unknown')}{context}\n",
    "\n",
    "Provide a helpful response. If this requires escalation, start your response with \"[ESCALATION NEEDED]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Check if escalation is needed\n",
    "    escalation_needed = response.content.startswith(\"[ESCALATION NEEDED]\")\n",
    "    \n",
    "    if escalation_needed:\n",
    "        print(\"   âš ï¸  Escalation required\")\n",
    "    else:\n",
    "        print(\"   âœ“ Response generated\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"support_agent_response\": response.content,\n",
    "        \"escalation_needed\": escalation_needed,\n",
    "        \"current_phase\": \"support_complete\",\n",
    "        \"agents_consulted\": state['agents_consulted'] + [\"support_agent\"]\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Support Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Response Synthesizer\n",
    "\n",
    "Combines responses from multiple agents into a coherent final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for synthesis\n",
    "synthesizer_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "def response_synthesizer(state: AgentState) -> AgentState:\n",
    "    \"\"\"Synthesize final response from all agent outputs\"\"\"\n",
    "    print(\"\\nðŸ”„ SYNTHESIZING RESPONSE\")\n",
    "    \n",
    "    # Collect all agent responses\n",
    "    responses = []\n",
    "    \n",
    "    if state.get('data_agent_response'):\n",
    "        responses.append(f\"Customer Data:\\n{state['data_agent_response']}\")\n",
    "    \n",
    "    if state.get('support_agent_response'):\n",
    "        responses.append(f\"Support Response:\\n{state['support_agent_response']}\")\n",
    "    \n",
    "    if not responses:\n",
    "        final_response = \"I apologize, but I was unable to process your request. Please try again or contact support.\"\n",
    "    elif len(responses) == 1:\n",
    "        # Single agent response\n",
    "        final_response = responses[0].split(':\\n', 1)[1]\n",
    "    else:\n",
    "        # Multi-agent response - synthesize\n",
    "        synthesis_prompt = f\"\"\"Combine these agent responses into a single, coherent customer service response:\n",
    "\n",
    "{chr(10).join(responses)}\n",
    "\n",
    "Create a professional, helpful response that:\n",
    "1. Addresses the customer's query directly\n",
    "2. Incorporates relevant information from all agents\n",
    "3. Maintains a friendly, professional tone\n",
    "4. Is concise and well-structured\n",
    "\"\"\"\n",
    "        \n",
    "        response = synthesizer_llm.invoke([\n",
    "            HumanMessage(content=synthesis_prompt)\n",
    "        ])\n",
    "        \n",
    "        final_response = response.content\n",
    "    \n",
    "    print(f\"   âœ“ Final response synthesized\")\n",
    "    print(f\"   Agents consulted: {', '.join(state['agents_consulted'])}\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"response\": final_response,\n",
    "        \"current_phase\": \"complete\"\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Response Synthesizer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build the Multi-Agent Workflow\n",
    "\n",
    "Connect all agents into a coordinated LangGraph workflow with conditional routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing logic functions\n",
    "def route_after_router(state: AgentState) -> List[str]:\n",
    "    \"\"\"Determine which agents to call after routing\"\"\"\n",
    "    agents_to_call = []\n",
    "    \n",
    "    if state.get('requires_data_agent'):\n",
    "        agents_to_call.append(\"data_agent\")\n",
    "    \n",
    "    if state.get('requires_support_agent'):\n",
    "        agents_to_call.append(\"support_agent\")\n",
    "    \n",
    "    # If no specific agent needed, default to support\n",
    "    if not agents_to_call:\n",
    "        agents_to_call.append(\"support_agent\")\n",
    "    \n",
    "    return agents_to_call\n",
    "\n",
    "def should_call_support_after_data(state: AgentState) -> str:\n",
    "    \"\"\"Decide if support agent needed after data agent\"\"\"\n",
    "    if state.get('requires_support_agent'):\n",
    "        return \"support_agent\"\n",
    "    return \"synthesizer\"\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"router\", router_agent)\n",
    "workflow.add_node(\"data_agent\", customer_data_agent)\n",
    "workflow.add_node(\"support_agent\", support_agent)\n",
    "workflow.add_node(\"synthesizer\", response_synthesizer)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"router\")\n",
    "\n",
    "# Conditional routing from router\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_after_router,\n",
    "    {\n",
    "        \"data_agent\": \"data_agent\",\n",
    "        \"support_agent\": \"support_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conditional routing from data agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"data_agent\",\n",
    "    should_call_support_after_data,\n",
    "    {\n",
    "        \"support_agent\": \"support_agent\",\n",
    "        \"synthesizer\": \"synthesizer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Support agent always goes to synthesizer\n",
    "workflow.add_edge(\"support_agent\", \"synthesizer\")\n",
    "\n",
    "# Synthesizer is the end\n",
    "workflow.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the graph\n",
    "customer_service_system = workflow.compile()\n",
    "\n",
    "print(\"âœ“ Multi-Agent Workflow compiled successfully\")\n",
    "print(\"\\nðŸ“Š Workflow Structure:\")\n",
    "print(\"   START â†’ Router â†’ [Data Agent] â†’ [Support Agent] â†’ Synthesizer â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Cases\n",
    "\n",
    "Demonstrate the system with various customer service scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 1: Account Information Query (Data Agent Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST CASE 1: Account Information Query\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = customer_service_system.invoke({\n",
    "    \"query\": \"Can you show me my account details and order history?\",\n",
    "    \"customer_identifier\": \"CUST001\",\n",
    "    \"current_phase\": \"initial\",\n",
    "    \"agents_consulted\": [],\n",
    "    \"escalation_needed\": False,\n",
    "    \"requires_data_agent\": False,\n",
    "    \"requires_support_agent\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result['response'])\n",
    "print(\"\\nEscalation needed:\", result['escalation_needed'])\n",
    "print(\"Agents consulted:\", ', '.join(result['agents_consulted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 2: Technical Support Query (Support Agent with Customer Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST CASE 2: Technical Support with Customer Context\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = customer_service_system.invoke({\n",
    "    \"query\": \"The product I received is defective and doesn't work as advertised. I need a replacement or refund.\",\n",
    "    \"customer_identifier\": \"alice.johnson@email.com\",\n",
    "    \"current_phase\": \"initial\",\n",
    "    \"agents_consulted\": [],\n",
    "    \"escalation_needed\": False,\n",
    "    \"requires_data_agent\": False,\n",
    "    \"requires_support_agent\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result['response'])\n",
    "print(\"\\nEscalation needed:\", result['escalation_needed'])\n",
    "print(\"Agents consulted:\", ', '.join(result['agents_consulted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 3: Enterprise Customer Issue (Escalation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST CASE 3: Enterprise Customer - Potential Escalation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = customer_service_system.invoke({\n",
    "    \"query\": \"We've been experiencing critical system outages affecting our business operations. This is unacceptable for an enterprise client. We need immediate resolution and compensation.\",\n",
    "    \"customer_identifier\": \"CUST002\",\n",
    "    \"current_phase\": \"initial\",\n",
    "    \"agents_consulted\": [],\n",
    "    \"escalation_needed\": False,\n",
    "    \"requires_data_agent\": False,\n",
    "    \"requires_support_agent\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result['response'])\n",
    "print(\"\\nEscalation needed:\", result['escalation_needed'])\n",
    "print(\"Agents consulted:\", ', '.join(result['agents_consulted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 4: General Inquiry (No Customer Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST CASE 4: General Inquiry - No Customer ID\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = customer_service_system.invoke({\n",
    "    \"query\": \"What are your business hours and shipping policies?\",\n",
    "    \"customer_identifier\": None,\n",
    "    \"current_phase\": \"initial\",\n",
    "    \"agents_consulted\": [],\n",
    "    \"escalation_needed\": False,\n",
    "    \"requires_data_agent\": False,\n",
    "    \"requires_support_agent\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result['response'])\n",
    "print(\"\\nEscalation needed:\", result['escalation_needed'])\n",
    "print(\"Agents consulted:\", ', '.join(result['agents_consulted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 5: Multi-Agent Coordination (Billing with Account Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST CASE 5: Complex Query - Multi-Agent Coordination\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result = customer_service_system.invoke({\n",
    "    \"query\": \"I was charged twice for my last order. Can you check my account and help me get a refund?\",\n",
    "    \"customer_identifier\": \"+1-555-0303\",\n",
    "    \"current_phase\": \"initial\",\n",
    "    \"agents_consulted\": [],\n",
    "    \"escalation_needed\": False,\n",
    "    \"requires_data_agent\": False,\n",
    "    \"requires_support_agent\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 80)\n",
    "print(result['response'])\n",
    "print(\"\\nEscalation needed:\", result['escalation_needed'])\n",
    "print(\"Agents consulted:\", ', '.join(result['agents_consulted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Demo\n",
    "\n",
    "Try your own queries with the customer service system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_customer_query(query: str, customer_id: str = None):\n",
    "    \"\"\"Process a customer service query through the multi-agent system\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROCESSING CUSTOMER QUERY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Query: {query}\")\n",
    "    if customer_id:\n",
    "        print(f\"Customer: {customer_id}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    result = customer_service_system.invoke({\n",
    "        \"query\": query,\n",
    "        \"customer_identifier\": customer_id,\n",
    "        \"current_phase\": \"initial\",\n",
    "        \"agents_consulted\": [],\n",
    "        \"escalation_needed\": False,\n",
    "        \"requires_data_agent\": False,\n",
    "        \"requires_support_agent\": False\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESPONSE\")\n",
    "    print(\"=\"*80)\n",
    "    print(result['response'])\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"Intent: {result.get('intent', 'N/A')}\")\n",
    "    print(f\"Agents: {', '.join(result['agents_consulted'])}\")\n",
    "    print(f\"Escalation: {'Yes' if result['escalation_needed'] else 'No'}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# process_customer_query(\n",
    "#     \"I want to upgrade my account to premium tier\",\n",
    "#     \"CUST003\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. System Analytics\n",
    "\n",
    "View metrics and performance of the multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_system_status():\n",
    "    \"\"\"Display current system status and statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-AGENT CUSTOMER SERVICE SYSTEM - STATUS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nðŸ“Š SYSTEM COMPONENTS:\")\n",
    "    print(\"   âœ“ Router Agent (Orchestrator)\")\n",
    "    print(\"   âœ“ Customer Data Agent (MCP-enabled)\")\n",
    "    print(\"   âœ“ Support Agent (Specialist)\")\n",
    "    print(\"   âœ“ Response Synthesizer\")\n",
    "    \n",
    "    print(\"\\nðŸ’¾ MCP SERVER STATUS:\")\n",
    "    print(f\"   Total Customers: {len(mcp_server.customers)}\")\n",
    "    \n",
    "    for cust_id, customer in mcp_server.customers.items():\n",
    "        print(f\"\\n   {cust_id}: {customer.name}\")\n",
    "        print(f\"      Tier: {customer.tier} | Status: {customer.account_status}\")\n",
    "        print(f\"      Orders: {customer.total_orders} | LTV: ${customer.lifetime_value:,.2f}\")\n",
    "        print(f\"      Open Tickets: {len([t for t in customer.support_tickets if t['status'] == 'open'])}\")\n",
    "    \n",
    "    print(\"\\nðŸ”§ CAPABILITIES:\")\n",
    "    print(\"   â€¢ Intent classification (6 categories)\")\n",
    "    print(\"   â€¢ Dynamic agent routing\")\n",
    "    print(\"   â€¢ Multi-agent coordination\")\n",
    "    print(\"   â€¢ Customer data retrieval via MCP\")\n",
    "    print(\"   â€¢ Automatic escalation detection\")\n",
    "    print(\"   â€¢ Context-aware responses\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "display_system_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Architecture Summary\n",
    "\n",
    "### System Flow:\n",
    "\n",
    "```\n",
    "1. CUSTOMER QUERY RECEIVED\n",
    "   â†“\n",
    "2. ROUTER AGENT\n",
    "   - Analyzes intent\n",
    "   - Extracts customer identifier\n",
    "   - Determines required agents\n",
    "   â†“\n",
    "3. SPECIALIST AGENTS (Parallel/Sequential)\n",
    "   \n",
    "   3a. CUSTOMER DATA AGENT (if needed)\n",
    "       - Connects to MCP server\n",
    "       - Retrieves customer data\n",
    "       - Validates information\n",
    "   \n",
    "   3b. SUPPORT AGENT (if needed)\n",
    "       - Uses customer context\n",
    "       - Generates solution\n",
    "       - Checks escalation criteria\n",
    "   â†“\n",
    "4. RESPONSE SYNTHESIZER\n",
    "   - Combines agent outputs\n",
    "   - Creates coherent response\n",
    "   - Formats final answer\n",
    "   â†“\n",
    "5. RESPONSE DELIVERED\n",
    "```\n",
    "\n",
    "### Key Technologies:\n",
    "- **LangGraph**: Multi-agent orchestration and state management\n",
    "- **OpenAI GPT-4**: Natural language understanding and generation\n",
    "- **MCP (Model Context Protocol)**: Standardized data access\n",
    "- **Pydantic**: Data validation and schema enforcement\n",
    "\n",
    "### Agent Communication (A2A):\n",
    "- Agents communicate through shared state\n",
    "- Router coordinates information flow\n",
    "- Support Agent can request data from Data Agent\n",
    "- All interactions logged for audit trail\n",
    "\n",
    "### Production Considerations:\n",
    "1. **Security**: Implement authentication, authorization, encryption\n",
    "2. **Scalability**: Add caching, load balancing, async processing\n",
    "3. **Monitoring**: Add logging, metrics, alerting\n",
    "4. **Error Handling**: Implement retry logic, fallbacks, circuit breakers\n",
    "5. **Data Privacy**: PII protection, GDPR compliance, data retention policies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
